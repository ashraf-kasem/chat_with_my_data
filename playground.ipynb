{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22f76399-713d-493c-bdb9-e87849b6942a",
   "metadata": {},
   "source": [
    "## **Chat with Your Data**\n",
    "#### Steps:\n",
    "- Process your documents (chunking, embedding, vector-store)\n",
    "- Q & A using our RAG\n",
    "  \n",
    "<br/>\n",
    "\n",
    "### **Process your documents (chunking, embedding, vector-store):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f147e57e-4ed5-40fe-aa63-920838d3d9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import fitz\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "# set the path to your data directory\n",
    "DATA_DIR = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2ca03cb7-8ffe-465d-ac33-01567598ee60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en import English \n",
    "\n",
    "# Add a sentencizer pipeline\n",
    "nlp = English()\n",
    "nlp.add_pipe(\"sentencizer\")\n",
    "\n",
    "def get_sentences(txt):\n",
    "    sentences = list(nlp(txt).sents)\n",
    "    sentences = [str(sentence) for sentence in sentences]\n",
    "    return sentences\n",
    "\n",
    "def read_files(data_dir):\n",
    "    # loop over your files\n",
    "    extracted_data = []\n",
    "    for file in glob.glob(os.path.join(data_dir, \"*.pdf\")):\n",
    "        # open the doc\n",
    "        document = fitz.open(file)\n",
    "        # process\n",
    "        # print(\"file path: \" , file)\n",
    "        for page_num, page in tqdm(enumerate(document)):\n",
    "            # get the raw text of each page\n",
    "            txt = page.get_text()\n",
    "            # do some cleaning\n",
    "            cleaned_text = txt.replace(\"\\n\", \" \").strip()\n",
    "            \n",
    "            # print(cleaned_text)\n",
    "            # print(\"\\n\\n ++++++++++++++++++++++++++++++++++ \\n\\n\")\n",
    "            sentences = get_sentences(cleaned_text)\n",
    "            entry = {\"file_path\": file,\n",
    "                     \"page_number\": page_num,\n",
    "                     \"page_char_count\": len(cleaned_text),\n",
    "                     \"page_word_count\": len(cleaned_text.split(\" \")),\n",
    "                     \"page_sentence_count\": len(sentences),\n",
    "                     \"page_token_count\": len(cleaned_text) / 4,\n",
    "                     \"text\": cleaned_text,\n",
    "                     \"sentences\": sentences}\n",
    "            extracted_data.append(entry)\n",
    "    return extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a5851c8f-ced2-4cba-9a25-7360b5ba5453",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [00:00, 94.26it/s] \n",
      "11it [00:00, 231.34it/s]\n",
      "19it [00:00, 148.26it/s]\n",
      "34it [00:00, 147.38it/s]\n"
     ]
    }
   ],
   "source": [
    "extracted_data = read_files(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c7669093-2b41-4328-9dbd-db2b222f36a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'file_path': 'data\\\\attention is all you need.pdf',\n",
       "  'page_number': 12,\n",
       "  'page_char_count': 812,\n",
       "  'page_word_count': 127,\n",
       "  'page_sentence_count': 8,\n",
       "  'page_token_count': 203.0,\n",
       "  'text': 'Attention Visualizations Input-Input Layer5 It is in this spirit that a majority of American governments have passed new laws since 2009 making the registration or voting process more difficult . <EOS> <pad> <pad> <pad> <pad> <pad> <pad> It is in this spirit that a majority of American governments have passed new laws since 2009 making the registration or voting process more difficult . <EOS> <pad> <pad> <pad> <pad> <pad> <pad> Figure 3: An example of the attention mechanism following long-distance dependencies in the encoder self-attention in layer 5 of 6. Many of the attention heads attend to a distant dependency of the verb ‘making’, completing the phrase ‘making...more difficult’. Attentions here shown only for the word ‘making’. Different colors represent different heads. Best viewed in color. 13',\n",
       "  'sentences': ['Attention Visualizations Input-Input Layer5 It is in this spirit that a majority of American governments have passed new laws since 2009 making the registration or voting process more difficult .',\n",
       "   '<EOS> <pad> <pad> <pad> <pad> <pad> <pad> It is in this spirit that a majority of American governments have passed new laws since 2009 making the registration or voting process more difficult .',\n",
       "   '<EOS> <pad> <pad> <pad> <pad> <pad> <pad> Figure 3: An example of the attention mechanism following long-distance dependencies in the encoder self-attention in layer 5 of 6.',\n",
       "   'Many of the attention heads attend to a distant dependency of the verb ‘making’, completing the phrase ‘making...more difficult’.',\n",
       "   'Attentions here shown only for the word ‘making’.',\n",
       "   'Different colors represent different heads.',\n",
       "   'Best viewed in color.',\n",
       "   '13']}]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random \n",
    "random.sample(extracted_data, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c506514e-20b5-4910-bddf-6d5de82da884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count</th>\n",
       "      <th>page_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>79.00</td>\n",
       "      <td>79.00</td>\n",
       "      <td>79.00</td>\n",
       "      <td>79.00</td>\n",
       "      <td>79.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>11.29</td>\n",
       "      <td>3299.86</td>\n",
       "      <td>507.87</td>\n",
       "      <td>28.14</td>\n",
       "      <td>824.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.75</td>\n",
       "      <td>1014.94</td>\n",
       "      <td>157.67</td>\n",
       "      <td>15.02</td>\n",
       "      <td>253.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>812.00</td>\n",
       "      <td>127.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>203.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.50</td>\n",
       "      <td>2615.50</td>\n",
       "      <td>428.50</td>\n",
       "      <td>18.00</td>\n",
       "      <td>653.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.00</td>\n",
       "      <td>3473.00</td>\n",
       "      <td>498.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>868.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>16.00</td>\n",
       "      <td>4007.00</td>\n",
       "      <td>629.00</td>\n",
       "      <td>35.00</td>\n",
       "      <td>1001.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>33.00</td>\n",
       "      <td>5391.00</td>\n",
       "      <td>849.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>1347.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  page_char_count  page_word_count  page_sentence_count  \\\n",
       "count        79.00            79.00            79.00                79.00   \n",
       "mean         11.29          3299.86           507.87                28.14   \n",
       "std           8.75          1014.94           157.67                15.02   \n",
       "min           0.00           812.00           127.00                 8.00   \n",
       "25%           4.50          2615.50           428.50                18.00   \n",
       "50%           9.00          3473.00           498.00                24.00   \n",
       "75%          16.00          4007.00           629.00                35.00   \n",
       "max          33.00          5391.00           849.00                64.00   \n",
       "\n",
       "       page_token_count  \n",
       "count             79.00  \n",
       "mean             824.97  \n",
       "std              253.74  \n",
       "min              203.00  \n",
       "25%              653.88  \n",
       "50%              868.25  \n",
       "75%             1001.75  \n",
       "max             1347.75  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(extracted_data)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed6652d-06c8-4e46-ae8b-316538b05675",
   "metadata": {},
   "source": [
    "#### **Chunking** \n",
    "We need to break the text into chunks then to embed these chunks and save them in the vectore-store. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "310ad16e-d45f-4ef2-877f-d4b061cb6a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# Define split size to turn groups of sentences into chunks\n",
    "CHUNK_SIZE_IN_SENTENCES = 10 \n",
    "\n",
    "def chunking(list_of_sentences, chunk_size):\n",
    "    # We group sentences based on the chunk size (estimated in sentences)\n",
    "    sentence_chunks = [list_of_sentences[i:i + chunk_size] for i in range(0, len(list_of_sentences), chunk_size)]\n",
    "    return sentence_chunks\n",
    "\n",
    "for entry in tqdm(extracted_data):\n",
    "    entry[\"sentence_chunks\"] = chunking(entry[\"sentences\"], CHUNK_SIZE_IN_SENTENCES)\n",
    "    entry[\"num_chunks\"] = len(entry[\"sentence_chunks\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "bb563600-5d9c-47ec-8bad-f76828dd37c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['For longer output sequences, |Y | can become large, requiring many forward passes.',\n",
       " 'For more efﬁcient decoding, we can make a further approximation that pθ(y|x, zi) ≈ 0 where y was not generated during beam search from x, zi.',\n",
       " 'This avoids the need to run additional forward passes once the candidate set Y has been generated.',\n",
       " 'We refer to this decoding procedure as “Fast Decoding.”',\n",
       " '3 Experiments We experiment with RAG in a wide range of knowledge-intensive tasks.',\n",
       " 'For all experiments, we use a single Wikipedia dump for our non-parametric knowledge source.',\n",
       " 'Following Lee et al. [',\n",
       " '31] and Karpukhin et al. [',\n",
       " '26], we use the December 2018 dump.',\n",
       " 'Each Wikipedia article is split into disjoint 100-word chunks, to make a total of 21M documents.']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(extracted_data, k=1)[0][\"sentence_chunks\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3ce95dd2-1b5d-47f8-b8a7-9fe042aa4fd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>num_chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>79.00</td>\n",
       "      <td>79.00</td>\n",
       "      <td>79.00</td>\n",
       "      <td>79.00</td>\n",
       "      <td>79.00</td>\n",
       "      <td>79.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>11.29</td>\n",
       "      <td>3299.86</td>\n",
       "      <td>507.87</td>\n",
       "      <td>28.14</td>\n",
       "      <td>824.97</td>\n",
       "      <td>3.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.75</td>\n",
       "      <td>1014.94</td>\n",
       "      <td>157.67</td>\n",
       "      <td>15.02</td>\n",
       "      <td>253.74</td>\n",
       "      <td>1.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>812.00</td>\n",
       "      <td>127.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>203.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.50</td>\n",
       "      <td>2615.50</td>\n",
       "      <td>428.50</td>\n",
       "      <td>18.00</td>\n",
       "      <td>653.88</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.00</td>\n",
       "      <td>3473.00</td>\n",
       "      <td>498.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>868.25</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>16.00</td>\n",
       "      <td>4007.00</td>\n",
       "      <td>629.00</td>\n",
       "      <td>35.00</td>\n",
       "      <td>1001.75</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>33.00</td>\n",
       "      <td>5391.00</td>\n",
       "      <td>849.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>1347.75</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  page_char_count  page_word_count  page_sentence_count  \\\n",
       "count        79.00            79.00            79.00                79.00   \n",
       "mean         11.29          3299.86           507.87                28.14   \n",
       "std           8.75          1014.94           157.67                15.02   \n",
       "min           0.00           812.00           127.00                 8.00   \n",
       "25%           4.50          2615.50           428.50                18.00   \n",
       "50%           9.00          3473.00           498.00                24.00   \n",
       "75%          16.00          4007.00           629.00                35.00   \n",
       "max          33.00          5391.00           849.00                64.00   \n",
       "\n",
       "       page_token_count  num_chunks  \n",
       "count             79.00       79.00  \n",
       "mean             824.97        3.25  \n",
       "std              253.74        1.55  \n",
       "min              203.00        1.00  \n",
       "25%              653.88        2.00  \n",
       "50%              868.25        3.00  \n",
       "75%             1001.75        4.00  \n",
       "max             1347.75        7.00  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(extracted_data)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfd4e89-1ac2-4ca3-89c8-426378b6f403",
   "metadata": {},
   "source": [
    "From the stats, we can see that the average num of chunks per page is 3, and the average token count is 807. we can conclude that each chunk has 807/3 ~ 269 tokens. meaning we need to choose an embedding model that has a context length >= 269. for example **all-mpnet-base-v2** model (it has a capacity of 384 tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03aa471-94d0-471f-9df1-a142cecc277d",
   "metadata": {},
   "source": [
    "Before going directly to creating the embedding locally, I need to filter some very short chunks, which could have not important info ex.(footer, links, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c2cbd647-d4d6-4347-9104-0c0bf3624464",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 14323.07it/s]\n"
     ]
    }
   ],
   "source": [
    "# create chunks dict to keep only chunks info\n",
    "def convert_to_chunck_dict(text_dict):  \n",
    "    extracted_chunks = []\n",
    "    for item in tqdm(text_dict):\n",
    "        for sentence_chunk in item[\"sentence_chunks\"]:\n",
    "            chunk_dict = {}\n",
    "            chunk_dict[\"file_path\"] = item[\"file_path\"]\n",
    "            chunk_dict[\"page_number\"] = item[\"page_number\"]\n",
    "            # Join the sentences together into a paragraph-like structure\n",
    "            joined_sentence_chunk = \"\".join(sentence_chunk).replace(\"  \", \" \").strip()\n",
    "            joined_sentence_chunk = re.sub(r'\\.([A-Z])', r'. \\1', joined_sentence_chunk) \n",
    "            chunk_dict[\"sentence_chunk\"] = joined_sentence_chunk\n",
    "            # Get stats about the chunk\n",
    "            chunk_dict[\"chunk_char_count\"] = len(joined_sentence_chunk)\n",
    "            chunk_dict[\"chunk_word_count\"] = len([word for word in joined_sentence_chunk.split(\" \")])\n",
    "            chunk_dict[\"chunk_token_count\"] = len(joined_sentence_chunk) / 4 # 1 token = ~4 characters\n",
    "            extracted_chunks.append(chunk_dict)\n",
    "    return extracted_chunks\n",
    "\n",
    "\n",
    "extracted_chunks = convert_to_chunck_dict(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8ef2ebbe-c7f3-454f-b6e3-09df7d04f01c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'file_path': 'data\\\\RAG.pdf',\n",
       "  'page_number': 12,\n",
       "  'sentence_chunk': 'for Computational Linguistics, pages 6086–6096, Florence, Italy, July 2019. Association for Computational Linguistics.doi: 10.18653/v1/P19-1612. URL https://www.aclweb.org/ anthology/P19-1612. [32] Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer. BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension.arXiv preprint arXiv:1910.13461, 2019. URL https://arxiv.org/abs/1910.13461. [33] Jiwei Li, Michel Galley, Chris Brockett, Jianfeng Gao, and Bill Dolan. A diversity-promoting objective function for neural conversation models.',\n",
       "  'chunk_char_count': 668,\n",
       "  'chunk_word_count': 71,\n",
       "  'chunk_token_count': 167.0}]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(extracted_chunks, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ac8befeb-85ba-42bd-b49d-5a057a35add0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>chunk_char_count</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>257.00</td>\n",
       "      <td>257.00</td>\n",
       "      <td>257.00</td>\n",
       "      <td>257.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>11.07</td>\n",
       "      <td>1012.51</td>\n",
       "      <td>154.96</td>\n",
       "      <td>253.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.70</td>\n",
       "      <td>595.98</td>\n",
       "      <td>99.55</td>\n",
       "      <td>148.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.00</td>\n",
       "      <td>604.00</td>\n",
       "      <td>78.00</td>\n",
       "      <td>151.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.00</td>\n",
       "      <td>852.00</td>\n",
       "      <td>133.00</td>\n",
       "      <td>213.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>14.00</td>\n",
       "      <td>1402.00</td>\n",
       "      <td>226.00</td>\n",
       "      <td>350.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>33.00</td>\n",
       "      <td>2798.00</td>\n",
       "      <td>469.00</td>\n",
       "      <td>699.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  chunk_char_count  chunk_word_count  chunk_token_count\n",
       "count       257.00            257.00            257.00             257.00\n",
       "mean         11.07           1012.51            154.96             253.13\n",
       "std           7.70            595.98             99.55             148.99\n",
       "min           0.00              1.00              1.00               0.25\n",
       "25%           6.00            604.00             78.00             151.00\n",
       "50%          10.00            852.00            133.00             213.00\n",
       "75%          14.00           1402.00            226.00             350.50\n",
       "max          33.00           2798.00            469.00             699.50"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get stats about our chunks\n",
    "df = pd.DataFrame(extracted_chunks)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "50b17ae0-72b5-43fa-a32e-8b74d0f9ff48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk token count: 28.0 | Text: In Proceedings of the 51st Annual Meeting of the ACL (Volume 1: Long Papers), pages 434–443. ACL, August 2013.12\n",
      "Chunk token count: 5.5 | Text: During inference, we 9\n",
      "Chunk token count: 18.75 | Text: doi: 10.1162/tacl_a_00030. URL https://www.aclweb.org/anthology/Q18-1031.11\n",
      "Chunk token count: 27.75 | Text: Another exciting research direction is to have the model predict future text as well as just the next action.34\n",
      "Chunk token count: 12.0 | Text: URL https://www.aclweb.org/anthology/P17-1020.10\n"
     ]
    }
   ],
   "source": [
    "# Show random chunks with under 30 tokens in length\n",
    "min_token_length = 30\n",
    "for row in df[df[\"chunk_token_count\"] <= min_token_length].sample(5).iterrows():\n",
    "    print(f'Chunk token count: {row[1][\"chunk_token_count\"]} | Text: {row[1][\"sentence_chunk\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f40b8c68-acb6-4385-99d7-f55e2b738f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_chunks_filtered = df[df[\"chunk_token_count\"] > min_token_length].to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4c01a402-f9ee-4bb4-ad86-a6dd830a4564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'file_path': 'data\\\\CNN.pdf',\n",
       "  'page_number': 6,\n",
       "  'sentence_chunk': 'Despite our best efforts so far we will still ﬁnd that our models are still enor- mous if we use an image input of any real dimensionality. However, methods have been developed as to greatly curtail the overall number of parameters within the convolutional layer. Parameter sharing works on the assumption that if one region feature is useful to compute at a set spatial region, then it is likely to be useful in another region. If we constrain each individual activation map within the output volume to the same weights and bias, then we will see a massive reduction in the number of parameters being produced by the convolutional layer. As a result of this as the backpropagation stage occurs, each neuron in the out- put will represent the overall gradient of which can be totalled across the depth - thus only updating a single set of weights, as opposed to every single one.',\n",
       "  'chunk_char_count': 879,\n",
       "  'chunk_word_count': 154,\n",
       "  'chunk_token_count': 219.75}]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(extracted_chunks_filtered, k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b98347-bc7a-4052-888e-01344d6a4429",
   "metadata": {},
   "source": [
    "#### **Embed chunks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3448feb5-4075-4be0-9ba3-fee8218cd6b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
