{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22f76399-713d-493c-bdb9-e87849b6942a",
   "metadata": {},
   "source": [
    "## **Chat with Your Data**\n",
    "#### Steps:\n",
    "- Process your documents (chunking, embedding, vector-store)\n",
    "- Q & A using our RAG\n",
    "  \n",
    "<br/>\n",
    "\n",
    "### **Process your documents (chunking, embedding, vector-store):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f147e57e-4ed5-40fe-aa63-920838d3d9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import fitz\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "# set the path to your data directory\n",
    "DATA_DIR = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ca03cb7-8ffe-465d-ac33-01567598ee60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en import English \n",
    "\n",
    "# Add a sentencizer pipeline\n",
    "nlp = English()\n",
    "nlp.add_pipe(\"sentencizer\")\n",
    "\n",
    "def get_sentences(txt):\n",
    "    sentences = list(nlp(txt).sents)\n",
    "    sentences = [str(sentence) for sentence in sentences]\n",
    "    return sentences\n",
    "\n",
    "def read_files(data_dir):\n",
    "    # loop over your files\n",
    "    extracted_data = []\n",
    "    for file in glob.glob(os.path.join(data_dir, \"*.pdf\")):\n",
    "        # open the doc\n",
    "        document = fitz.open(file)\n",
    "        # process\n",
    "        # print(\"file path: \" , file)\n",
    "        for page_num, page in tqdm(enumerate(document)):\n",
    "            # get the raw text of each page\n",
    "            txt = page.get_text()\n",
    "            # do some cleaning\n",
    "            cleaned_text = txt.replace(\"\\n\", \" \").strip()\n",
    "            \n",
    "            # print(cleaned_text)\n",
    "            # print(\"\\n\\n ++++++++++++++++++++++++++++++++++ \\n\\n\")\n",
    "            sentences = get_sentences(cleaned_text)\n",
    "            entry = {\"file_path\": file,\n",
    "                     \"page_number\": page_num,\n",
    "                     \"page_char_count\": len(cleaned_text),\n",
    "                     \"page_word_count\": len(cleaned_text.split(\" \")),\n",
    "                     \"page_sentence_count\": len(sentences),\n",
    "                     \"page_token_count\": len(cleaned_text) / 4,\n",
    "                     \"text\": cleaned_text,\n",
    "                     \"sentences\": sentences}\n",
    "            extracted_data.append(entry)\n",
    "    return extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5851c8f-ced2-4cba-9a25-7360b5ba5453",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [00:00, 84.15it/s] \n",
      "11it [00:00, 226.97it/s]\n",
      "19it [00:00, 136.28it/s]\n",
      "34it [00:00, 132.00it/s]\n"
     ]
    }
   ],
   "source": [
    "extracted_data = read_files(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7669093-2b41-4328-9dbd-db2b222f36a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'file_path': 'data\\\\video pretraining VPT.pdf',\n",
       "  'page_number': 8,\n",
       "  'page_char_count': 3716,\n",
       "  'page_word_count': 588,\n",
       "  'page_sentence_count': 24,\n",
       "  'page_token_count': 929.0,\n",
       "  'text': 'Trained on Contractor Data Trained on IDM Labeled Web Data Figure 8: (Left) Zero-shot rollout performance of foundation models trained on varying amounts of data. Models to the left of the dashed black line (points ≤1k hours) were trained on contractor data (ground-truth labels), and models to the right were trained on IDM pseudo-labeled subsets of web_clean. Due to compute limitations, this analysis was performed with smaller (71 million parameter) models except for the final point, which is the 0.5 billion parameter VPT foundation model. (Right) The corresponding performance of each model after BC fine-tuning each model to the contractor_house dataset. contractor data, and those trained on 5k hours and above are trained on subsets of web_clean, which does not contain any IDM contractor data. Scaling training data increases log collection, mining, and crafting capabilities. The zero-shot model only begins to start crafting crafting tables at over 5000 hours of training data. When fine-tuning each foundation model to contractor_house, we see that crafting rates for crafting tables and wooden tools increase by orders of magnitude when using the entire ∼70k hour web_clean dataset. We furthermore only see the emergence of crafting stone tools at the largest data scale. 4.6 Effect of Inverse Dynamics Model Quality on Behavioral Cloning Figure 9: Zero-shot performance of BC models trained from scratch on the earlygame_keyword dataset labeled with IDMs that were trained on increasing amounts of contractor data. This section investigates how downstream BC performance is affected by IDM qual- ity. We train IDMs on increasingly larger datasets and use each to independently label the earlygame_keyword dataset (this smaller dataset was chosen due to a limited compute bud- get). We then train a BC model from scratch on each dataset and report game statistics for each model as a function of IDM contractor dataset size (Fig. 9). IDMs trained on at least 10 hours of data are required for any crafting, and the crafting rate increases quickly up until 100 hours of data, after which there are few to no gains and differences are likely due to noise. Similarly, crafting tables are only crafted after 50 or more hours of IDM data, and again gains plateau after 100 hours. While in all previous experiments we use our best IDM trained on 1962 hours of data, these results suggest we could reduce that number to as low as 100 hours. 5 Discussion and Conclusion The results presented in this paper help pave the path to utilizing the wealth of unlabeled data on the web for sequential decision domains. Compared to generative video modeling or contrastive methods that would only yield representational priors, VPT offers the exciting possibility of directly learning to act during pretraining and using these learned behavioral priors as extremely effective exploration priors for RL. VPT could even be a better general representation learning method even when the downstream task is not learning to act in that domain—for example, fine-tuning to explain what is happening in a video—because arguably the most important information in any given scene would be present in features trained to correctly predict the distribution over future human actions. We leave this intriguing direction to future work. Future work could improve results with more data (we estimate we could collect >1M hours) and larger, better-tuned models. Furthermore, all the models in this work condition on past observations only; we cannot ask the model to perform specific tasks. Appendix I presents preliminary experiments on conditioning our models on closed captions (text transcripts of speech in videos), showing they 9',\n",
       "  'sentences': ['Trained on Contractor Data Trained on IDM Labeled Web Data Figure 8: (Left) Zero-shot rollout performance of foundation models trained on varying amounts of data.',\n",
       "   'Models to the left of the dashed black line (points ≤1k hours) were trained on contractor data (ground-truth labels), and models to the right were trained on IDM pseudo-labeled subsets of web_clean.',\n",
       "   'Due to compute limitations, this analysis was performed with smaller (71 million parameter) models except for the final point, which is the 0.5 billion parameter VPT foundation model. (',\n",
       "   'Right) The corresponding performance of each model after BC fine-tuning each model to the contractor_house dataset.',\n",
       "   'contractor data, and those trained on 5k hours and above are trained on subsets of web_clean, which does not contain any IDM contractor data.',\n",
       "   'Scaling training data increases log collection, mining, and crafting capabilities.',\n",
       "   'The zero-shot model only begins to start crafting crafting tables at over 5000 hours of training data.',\n",
       "   'When fine-tuning each foundation model to contractor_house, we see that crafting rates for crafting tables and wooden tools increase by orders of magnitude when using the entire ∼70k hour web_clean dataset.',\n",
       "   'We furthermore only see the emergence of crafting stone tools at the largest data scale.',\n",
       "   '4.6 Effect of Inverse Dynamics Model Quality on Behavioral Cloning Figure 9: Zero-shot performance of BC models trained from scratch on the earlygame_keyword dataset labeled with IDMs that were trained on increasing amounts of contractor data.',\n",
       "   'This section investigates how downstream BC performance is affected by IDM qual- ity.',\n",
       "   'We train IDMs on increasingly larger datasets and use each to independently label the earlygame_keyword dataset (this smaller dataset was chosen due to a limited compute bud- get).',\n",
       "   'We then train a BC model from scratch on each dataset and report game statistics for each model as a function of IDM contractor dataset size (Fig.',\n",
       "   '9).',\n",
       "   'IDMs trained on at least 10 hours of data are required for any crafting, and the crafting rate increases quickly up until 100 hours of data, after which there are few to no gains and differences are likely due to noise.',\n",
       "   'Similarly, crafting tables are only crafted after 50 or more hours of IDM data, and again gains plateau after 100 hours.',\n",
       "   'While in all previous experiments we use our best IDM trained on 1962 hours of data, these results suggest we could reduce that number to as low as 100 hours.',\n",
       "   '5 Discussion and Conclusion The results presented in this paper help pave the path to utilizing the wealth of unlabeled data on the web for sequential decision domains.',\n",
       "   'Compared to generative video modeling or contrastive methods that would only yield representational priors, VPT offers the exciting possibility of directly learning to act during pretraining and using these learned behavioral priors as extremely effective exploration priors for RL.',\n",
       "   'VPT could even be a better general representation learning method even when the downstream task is not learning to act in that domain—for example, fine-tuning to explain what is happening in a video—because arguably the most important information in any given scene would be present in features trained to correctly predict the distribution over future human actions.',\n",
       "   'We leave this intriguing direction to future work.',\n",
       "   'Future work could improve results with more data (we estimate we could collect >1M hours) and larger, better-tuned models.',\n",
       "   'Furthermore, all the models in this work condition on past observations only; we cannot ask the model to perform specific tasks.',\n",
       "   'Appendix I presents preliminary experiments on conditioning our models on closed captions (text transcripts of speech in videos), showing they 9']}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random \n",
    "random.sample(extracted_data, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c506514e-20b5-4910-bddf-6d5de82da884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count</th>\n",
       "      <th>page_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>79.00</td>\n",
       "      <td>79.00</td>\n",
       "      <td>79.00</td>\n",
       "      <td>79.00</td>\n",
       "      <td>79.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>11.29</td>\n",
       "      <td>3299.86</td>\n",
       "      <td>507.87</td>\n",
       "      <td>28.14</td>\n",
       "      <td>824.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.75</td>\n",
       "      <td>1014.94</td>\n",
       "      <td>157.67</td>\n",
       "      <td>15.02</td>\n",
       "      <td>253.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>812.00</td>\n",
       "      <td>127.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>203.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.50</td>\n",
       "      <td>2615.50</td>\n",
       "      <td>428.50</td>\n",
       "      <td>18.00</td>\n",
       "      <td>653.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.00</td>\n",
       "      <td>3473.00</td>\n",
       "      <td>498.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>868.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>16.00</td>\n",
       "      <td>4007.00</td>\n",
       "      <td>629.00</td>\n",
       "      <td>35.00</td>\n",
       "      <td>1001.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>33.00</td>\n",
       "      <td>5391.00</td>\n",
       "      <td>849.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>1347.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  page_char_count  page_word_count  page_sentence_count  \\\n",
       "count        79.00            79.00            79.00                79.00   \n",
       "mean         11.29          3299.86           507.87                28.14   \n",
       "std           8.75          1014.94           157.67                15.02   \n",
       "min           0.00           812.00           127.00                 8.00   \n",
       "25%           4.50          2615.50           428.50                18.00   \n",
       "50%           9.00          3473.00           498.00                24.00   \n",
       "75%          16.00          4007.00           629.00                35.00   \n",
       "max          33.00          5391.00           849.00                64.00   \n",
       "\n",
       "       page_token_count  \n",
       "count             79.00  \n",
       "mean             824.97  \n",
       "std              253.74  \n",
       "min              203.00  \n",
       "25%              653.88  \n",
       "50%              868.25  \n",
       "75%             1001.75  \n",
       "max             1347.75  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(extracted_data)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed6652d-06c8-4e46-ae8b-316538b05675",
   "metadata": {},
   "source": [
    "#### **Chunking** \n",
    "We need to break the text into chunks then to embed these chunks and save them in the vectore-store. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "310ad16e-d45f-4ef2-877f-d4b061cb6a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 78930.45it/s]\n"
     ]
    }
   ],
   "source": [
    "# Define split size to turn groups of sentences into chunks\n",
    "CHUNK_SIZE_IN_SENTENCES = 5 \n",
    "\n",
    "def chunking(list_of_sentences, chunk_size):\n",
    "    # We group sentences based on the chunk size (estimated in sentences)\n",
    "    sentence_chunks = [list_of_sentences[i:i + chunk_size] for i in range(0, len(list_of_sentences), chunk_size)]\n",
    "    return sentence_chunks\n",
    "\n",
    "for entry in tqdm(extracted_data):\n",
    "    entry[\"sentence_chunks\"] = chunking(entry[\"sentences\"], CHUNK_SIZE_IN_SENTENCES)\n",
    "    entry[\"num_chunks\"] = len(entry[\"sentence_chunks\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb563600-5d9c-47ec-8bad-f76828dd37c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Our model achieves 28.4 BLEU on the WMT 2014 English- to-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU.',\n",
       " 'On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature.',\n",
       " 'We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.',\n",
       " '∗Equal contribution.',\n",
       " 'Listing order is random.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(extracted_data, k=1)[0][\"sentence_chunks\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ce95dd2-1b5d-47f8-b8a7-9fe042aa4fd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>num_chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>79.00</td>\n",
       "      <td>79.00</td>\n",
       "      <td>79.00</td>\n",
       "      <td>79.00</td>\n",
       "      <td>79.00</td>\n",
       "      <td>79.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>11.29</td>\n",
       "      <td>3299.86</td>\n",
       "      <td>507.87</td>\n",
       "      <td>28.14</td>\n",
       "      <td>824.97</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.75</td>\n",
       "      <td>1014.94</td>\n",
       "      <td>157.67</td>\n",
       "      <td>15.02</td>\n",
       "      <td>253.74</td>\n",
       "      <td>3.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>812.00</td>\n",
       "      <td>127.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>203.00</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.50</td>\n",
       "      <td>2615.50</td>\n",
       "      <td>428.50</td>\n",
       "      <td>18.00</td>\n",
       "      <td>653.88</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.00</td>\n",
       "      <td>3473.00</td>\n",
       "      <td>498.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>868.25</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>16.00</td>\n",
       "      <td>4007.00</td>\n",
       "      <td>629.00</td>\n",
       "      <td>35.00</td>\n",
       "      <td>1001.75</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>33.00</td>\n",
       "      <td>5391.00</td>\n",
       "      <td>849.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>1347.75</td>\n",
       "      <td>13.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  page_char_count  page_word_count  page_sentence_count  \\\n",
       "count        79.00            79.00            79.00                79.00   \n",
       "mean         11.29          3299.86           507.87                28.14   \n",
       "std           8.75          1014.94           157.67                15.02   \n",
       "min           0.00           812.00           127.00                 8.00   \n",
       "25%           4.50          2615.50           428.50                18.00   \n",
       "50%           9.00          3473.00           498.00                24.00   \n",
       "75%          16.00          4007.00           629.00                35.00   \n",
       "max          33.00          5391.00           849.00                64.00   \n",
       "\n",
       "       page_token_count  num_chunks  \n",
       "count             79.00       79.00  \n",
       "mean             824.97        6.00  \n",
       "std              253.74        3.04  \n",
       "min              203.00        2.00  \n",
       "25%              653.88        4.00  \n",
       "50%              868.25        5.00  \n",
       "75%             1001.75        7.00  \n",
       "max             1347.75       13.00  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(extracted_data)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfd4e89-1ac2-4ca3-89c8-426378b6f403",
   "metadata": {},
   "source": [
    "From the stats, we can see that the average num of chunks per page is 3, and the average token count is 807. we can conclude that each chunk has 807/3 ~ 269 tokens. meaning we need to choose an embedding model that has a context length >= 269. for example **all-mpnet-base-v2** model (it has a capacity of 384 tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03aa471-94d0-471f-9df1-a142cecc277d",
   "metadata": {},
   "source": [
    "Before going directly to creating the embedding locally, I need to filter some very short chunks, which could have not important info ex.(footer, links, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2cbd647-d4d6-4347-9104-0c0bf3624464",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 13172.33it/s]\n"
     ]
    }
   ],
   "source": [
    "# create chunks dict to keep only chunks info\n",
    "def convert_to_chunck_dict(text_dict):  \n",
    "    extracted_chunks = []\n",
    "    for item in tqdm(text_dict):\n",
    "        for sentence_chunk in item[\"sentence_chunks\"]:\n",
    "            chunk_dict = {}\n",
    "            chunk_dict[\"file_path\"] = item[\"file_path\"]\n",
    "            chunk_dict[\"page_number\"] = item[\"page_number\"]\n",
    "            # Join the sentences together into a paragraph-like structure\n",
    "            joined_sentence_chunk = \"\".join(sentence_chunk).replace(\"  \", \" \").strip()\n",
    "            joined_sentence_chunk = re.sub(r'\\.([A-Z])', r'. \\1', joined_sentence_chunk) \n",
    "            chunk_dict[\"sentence_chunk\"] = joined_sentence_chunk\n",
    "            # Get stats about the chunk\n",
    "            chunk_dict[\"chunk_char_count\"] = len(joined_sentence_chunk)\n",
    "            chunk_dict[\"chunk_word_count\"] = len([word for word in joined_sentence_chunk.split(\" \")])\n",
    "            chunk_dict[\"chunk_token_count\"] = len(joined_sentence_chunk) / 4 # 1 token = ~4 characters\n",
    "            extracted_chunks.append(chunk_dict)\n",
    "    return extracted_chunks\n",
    "\n",
    "\n",
    "extracted_chunks = convert_to_chunck_dict(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ef2ebbe-c7f3-454f-b6e3-09df7d04f01c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'file_path': 'data\\\\RAG.pdf',\n",
       "  'page_number': 5,\n",
       "  'sentence_chunk': 'BART completes the generation \"The Sun Also Rises\" is a novel by this author of \"The Sun Also Rises\" indicating the title \"The Sun Also Rises\" is stored in BART’s parameters. Similarly, BART will complete the partial decoding \"The Sun Also Rises\" is a novel by this author of \"A with \"The Sun Also Rises\" is a novel by this author of \"A Farewell to Arms\". This example shows how parametric and non-parametric memories work together—the non-parametric component helps to guide the generation, drawing out speciﬁc knowledge stored in the parametric memory.4.4 Fact Veriﬁcation Table 2 shows our results on FEVER. For 3-way classiﬁcation, RAG scores are within 4.3% of state-of-the-art models, which are complex pipeline systems with domain-speciﬁc architectures and substantial engineering, trained using intermediate retrieval supervision, which RAG does not require.',\n",
       "  'chunk_char_count': 866,\n",
       "  'chunk_word_count': 133,\n",
       "  'chunk_token_count': 216.5}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(extracted_chunks, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac8befeb-85ba-42bd-b49d-5a057a35add0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>chunk_char_count</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>474.00</td>\n",
       "      <td>474.00</td>\n",
       "      <td>474.00</td>\n",
       "      <td>474.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>11.13</td>\n",
       "      <td>548.66</td>\n",
       "      <td>84.16</td>\n",
       "      <td>137.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.61</td>\n",
       "      <td>321.96</td>\n",
       "      <td>53.99</td>\n",
       "      <td>80.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.00</td>\n",
       "      <td>314.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>78.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.00</td>\n",
       "      <td>477.50</td>\n",
       "      <td>75.00</td>\n",
       "      <td>119.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>14.00</td>\n",
       "      <td>763.00</td>\n",
       "      <td>120.00</td>\n",
       "      <td>190.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>33.00</td>\n",
       "      <td>1905.00</td>\n",
       "      <td>296.00</td>\n",
       "      <td>476.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  chunk_char_count  chunk_word_count  chunk_token_count\n",
       "count       474.00            474.00            474.00             474.00\n",
       "mean         11.13            548.66             84.16             137.17\n",
       "std           7.61            321.96             53.99              80.49\n",
       "min           0.00              1.00              1.00               0.25\n",
       "25%           6.00            314.00             40.00              78.50\n",
       "50%          10.00            477.50             75.00             119.38\n",
       "75%          14.00            763.00            120.00             190.75\n",
       "max          33.00           1905.00            296.00             476.25"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get stats about our chunks\n",
    "df = pd.DataFrame(extracted_chunks)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50b17ae0-72b5-43fa-a32e-8b74d0f9ff48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk token count: 6.75 | Text: We only collected labels 17\n",
      "Chunk token count: 1.75 | Text: 1960.13\n",
      "Chunk token count: 10.0 | Text: arXiv preprint arXiv:1508.04025, 2015.11\n",
      "Chunk token count: 22.5 | Text: Later in the project, as we needed more data and as some contractors asked to terminate 19\n",
      "Chunk token count: 25.25 | Text: Curran Associates, Inc., 2015. URL http://papers.nips.cc/paper/5846-end-to-end-memory-networks.pdf.14\n"
     ]
    }
   ],
   "source": [
    "# Show random chunks with under 30 tokens in length\n",
    "min_token_length = 30\n",
    "for row in df[df[\"chunk_token_count\"] <= min_token_length].sample(5).iterrows():\n",
    "    print(f'Chunk token count: {row[1][\"chunk_token_count\"]} | Text: {row[1][\"sentence_chunk\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f40b8c68-acb6-4385-99d7-f55e2b738f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_chunks_filtered = df[df[\"chunk_token_count\"] > min_token_length].to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c01a402-f9ee-4bb4-ad86-a6dd830a4564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'file_path': 'data\\\\RAG.pdf',\n",
       "  'page_number': 2,\n",
       "  'sentence_chunk': '2.1 Models RAG-Sequence Model The RAG-Sequence model uses the same retrieved document to generate the complete sequence. Technically, it treats the retrieved document as a single latent variable that is marginalized to get the seq2seq probability p(y|x) via a top-K approximation. Concretely, the top K documents are retrieved using the retriever, and the generator produces the output sequence probability for each document, which are then marginalized, pRAG-Sequence(y|x) ≈ X z∈top-k(p(·|x)) pη(z|x)pθ(y|x, z) = X z∈top-k(p(·|x)) pη(z|x) N Y i pθ(yi|x, z, y1:i−1) RAG-Token Model In the RAG-Token model we can draw a different latent document for each target token and marginalize accordingly. This allows the generator to choose content from several documents when producing an answer. Concretely, the top K documents are retrieved using the retriever, and then the generator produces a distribution for the next output token for each document, before marginalizing, and repeating the process with the following output token, Formally, we deﬁne: pRAG-Token(y|x) ≈ N Y i X z∈top-k(p(·|x)) pη(z|x)pθ(yi|x, z, y1:i−1) Finally, we note that RAG can be used for sequence classiﬁcation tasks by considering the target class as a target sequence of length one, in which case RAG-Sequence and RAG-Token are equivalent.',\n",
       "  'chunk_char_count': 1313,\n",
       "  'chunk_word_count': 197,\n",
       "  'chunk_token_count': 328.25}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(extracted_chunks_filtered, k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b98347-bc7a-4052-888e-01344d6a4429",
   "metadata": {},
   "source": [
    "#### **Embed chunks**\n",
    " import a text embedding model **all-mpnet-base-v2** which outputs vectors of size **768**. With a context length of **384** tokens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ea90d00-286c-4669-8ef2-88cd140ef81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ashraf\\PycharmProjects\\chat_with_my_data\\venv\\lib\\site-packages\\huggingface_hub\\file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Ashraf\\PycharmProjects\\chat_with_my_data\\venv\\lib\\site-packages\\huggingface_hub\\file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding shape:  (768,)\n",
      "embedding values:  [-2.98330616e-02 -9.65827703e-02  9.01226245e-04  7.41711119e-03\n",
      " -4.27282527e-02  2.93111559e-02 -8.72458238e-03  8.85402597e-03\n",
      "  3.43042314e-02 -9.74845886e-03  6.65283054e-02 -1.87870618e-02\n",
      "  3.86397354e-02 -2.12698132e-02  1.95645131e-02 -4.51359116e-02\n",
      "  4.06676419e-02 -3.41284163e-02 -2.89035011e-02  1.64026618e-02\n",
      " -5.03091551e-02  2.55158283e-02 -1.66003518e-02 -6.22245744e-02\n",
      " -2.18643956e-02  8.85844044e-03 -4.52556312e-02 -3.97380888e-02\n",
      "  5.33500360e-03 -1.09222541e-02  2.95482390e-02 -1.83249377e-02\n",
      "  1.36156548e-02 -4.51841801e-02  1.41395890e-06  9.03561246e-03\n",
      " -2.42098961e-02 -1.42207881e-02 -1.03771966e-03  1.08437771e-02\n",
      "  4.88634109e-02  2.92940773e-02  1.86034199e-02  4.02783975e-02\n",
      " -2.57998984e-02  6.53411495e-03  4.77776714e-02  2.44616047e-02\n",
      " -2.95096375e-02  7.03382939e-02  1.46438566e-03 -7.21641025e-03\n",
      "  2.66191293e-03 -4.00283672e-02  6.15323633e-02  5.02035860e-03\n",
      "  1.76253971e-02  3.06243580e-02 -2.64169946e-02  7.21851662e-02\n",
      " -2.74050585e-03  1.72595531e-02 -1.13733690e-02  1.45569965e-02\n",
      " -5.75454310e-02 -1.62421092e-02  4.72011007e-02  6.66819187e-03\n",
      "  1.43896695e-02  1.11306049e-02  4.97758128e-02 -5.54345846e-02\n",
      "  3.08897384e-02  7.52025470e-02 -1.57245900e-02  1.03884609e-02\n",
      "  3.02233957e-02 -8.11304152e-03  4.64445688e-02  2.36623678e-02\n",
      "  7.03683347e-02  2.62743272e-02 -2.85178283e-03  1.71326902e-02\n",
      " -1.10882167e-02  3.45767587e-02 -1.66675188e-02 -2.73128948e-03\n",
      " -7.00471848e-02  9.41952784e-03 -2.60145981e-02 -5.35756163e-02\n",
      "  2.35649310e-02  4.64965738e-02  1.92652065e-02 -2.05820072e-02\n",
      " -3.62912193e-03 -9.32938755e-02  1.72505323e-02 -4.60119545e-02\n",
      " -6.48443997e-02 -3.03216260e-02 -2.72609945e-02  1.56775527e-02\n",
      " -4.20573540e-02  6.15798126e-06  2.80843154e-02  1.18430788e-02\n",
      " -2.90912930e-02 -3.43550257e-02  6.73495745e-03 -1.98679287e-02\n",
      " -4.17229906e-02  1.14097921e-02  1.54305901e-02 -1.05539486e-02\n",
      "  3.22454013e-02 -4.23965305e-02  2.95407735e-02  2.16282345e-02\n",
      " -6.45936057e-02 -1.48806404e-02  1.64957775e-03  6.39089718e-02\n",
      "  4.62845666e-03  5.14550358e-02 -5.08311689e-02 -9.54131223e-03\n",
      "  2.99538746e-02  2.99632326e-02  1.43412198e-03  1.22411847e-02\n",
      "  3.16693299e-02  6.97938958e-03  4.73447423e-03  4.45800461e-02\n",
      "  2.87673250e-02 -2.16939915e-02 -1.15821119e-02 -8.44330247e-03\n",
      " -2.63252016e-02 -2.31862850e-02 -1.54718487e-02  5.54384179e-02\n",
      "  1.67416334e-02  2.65355576e-02 -5.68099460e-03 -7.53076747e-02\n",
      " -1.37405723e-05  1.31234468e-03  2.97575705e-02  1.73881114e-03\n",
      " -3.20667364e-02 -2.68734223e-03  2.25521391e-03  4.89485171e-03\n",
      "  2.35521365e-02 -5.80904167e-03  1.79930702e-02 -1.82994064e-02\n",
      "  2.67358925e-02 -7.28821754e-03  4.97680111e-03 -3.69876549e-02\n",
      "  2.59637870e-02  5.57879312e-03 -3.28047760e-02 -2.91453358e-02\n",
      " -2.31534243e-02  1.04103992e-02  4.22285777e-03  1.94323007e-02\n",
      "  3.04787103e-02  4.05750871e-02  2.86506377e-02  6.60413280e-02\n",
      " -2.56627295e-02  4.67639267e-02 -3.28106992e-02  2.00818349e-02\n",
      "  3.85910347e-02 -5.00458255e-02 -1.70967672e-02  3.53389606e-02\n",
      " -4.58675027e-02  5.51809967e-02  2.32508518e-02 -3.03005874e-02\n",
      " -1.09771662e-03 -4.92648035e-02 -1.11079654e-02  2.96835285e-02\n",
      "  6.57986663e-03  1.96838565e-02  1.71703263e-03 -2.44273823e-02\n",
      "  2.23258208e-03  3.93276662e-02 -5.53918742e-02 -4.75524180e-02\n",
      "  3.72894891e-02  8.39849636e-02  3.63749191e-02  2.35375240e-02\n",
      " -1.33202476e-02 -2.90303584e-02  4.88082133e-02 -2.74531431e-02\n",
      "  1.61647312e-02  3.60512664e-03  4.90250289e-02  2.46681981e-02\n",
      " -2.26002727e-02 -5.16787637e-04  1.78205669e-02 -9.35656019e-03\n",
      "  3.91361862e-03 -2.21933257e-02 -5.46029815e-03  4.62081172e-02\n",
      " -4.38269153e-02 -2.78947479e-03 -3.03243846e-02  7.22652022e-03\n",
      "  5.71062416e-03 -5.35193160e-02 -7.31087476e-02 -2.69110538e-02\n",
      " -6.32478669e-02 -2.56544687e-02  1.34294834e-02  3.94732244e-02\n",
      " -2.32932214e-02  4.32260893e-02 -8.24286416e-02  3.77368648e-03\n",
      " -1.78255711e-03  8.09249654e-03  1.44575192e-02 -5.65609932e-02\n",
      " -1.59773771e-02  2.27565039e-02  7.44304433e-03  7.93026481e-03\n",
      "  1.32432161e-02 -7.31714256e-03  5.16308174e-02  1.63043085e-02\n",
      "  2.85571385e-02 -2.55156159e-02 -2.70522032e-02 -1.01262176e-05\n",
      " -4.13383320e-02  1.52197015e-02  5.70383519e-02  3.56647000e-02\n",
      "  2.55209059e-02 -3.10022719e-02  6.86892644e-02  1.81103311e-02\n",
      "  2.02808250e-02 -2.41701826e-02 -1.23376772e-02 -3.68077978e-02\n",
      " -4.08546850e-02  5.06121293e-03  3.91345378e-03 -2.18389463e-02\n",
      " -5.77984303e-02 -6.72161952e-03  1.54773863e-02  6.88161654e-03\n",
      " -1.40049635e-02 -8.35078117e-03 -3.22665414e-03  4.92964173e-03\n",
      "  3.94267542e-03 -3.27960798e-03 -9.29788873e-03  1.26796756e-02\n",
      " -1.97433513e-02 -2.35488769e-02 -4.30702046e-02  8.88391957e-03\n",
      " -3.09070759e-02  5.86693957e-02  3.74797024e-02  1.53481914e-02\n",
      "  1.26260733e-02  4.40668985e-02  3.03448252e-02  1.34260794e-02\n",
      "  1.23271570e-02 -9.39545222e-03  1.69914272e-02 -1.02797328e-02\n",
      "  3.44085284e-02 -4.30861115e-02  3.01463418e-02  2.91514248e-02\n",
      " -2.16601919e-02 -4.78986278e-02  4.53172773e-02 -1.52440602e-02\n",
      " -3.58839035e-02  5.32750487e-02  1.85794830e-02 -6.54990003e-02\n",
      " -3.11341099e-02  3.71725149e-02  3.98911871e-02 -1.12505853e-02\n",
      " -2.15154774e-02 -5.08596608e-03 -5.45822605e-02 -3.41570051e-03\n",
      "  7.27999257e-04 -9.15997662e-03 -3.83412316e-02 -2.35604681e-03\n",
      " -3.38468840e-03 -6.86001778e-03 -3.09210084e-02 -1.78853739e-02\n",
      "  3.36235315e-02 -9.07295123e-02  6.80541545e-02  1.88148804e-02\n",
      "  1.17000658e-02 -4.73259166e-02 -2.01868117e-02  2.48852894e-02\n",
      " -2.84433234e-02  1.11787573e-01  8.61762371e-03  6.45247549e-02\n",
      " -2.93037072e-02  2.72400565e-02 -7.30018392e-02 -5.86080505e-03\n",
      " -5.97490976e-03  2.29172390e-02  2.74711978e-02  8.67631659e-03\n",
      "  2.61610877e-02  2.07428038e-02  4.41226829e-03 -5.17778397e-02\n",
      " -3.94385904e-02 -3.23408470e-02  1.01538729e-02  4.63550873e-02\n",
      " -9.72621422e-03  2.51008593e-03 -1.11923665e-02 -2.11037733e-02\n",
      "  5.81581797e-03  2.09335331e-02 -1.30687384e-02 -3.12562920e-02\n",
      "  3.49655524e-02  1.56337954e-02 -8.52407217e-02  4.45583761e-02\n",
      "  2.13739052e-02  1.26655512e-02  5.66022564e-03  3.59553508e-02\n",
      "  2.01072060e-02  3.06013618e-02  4.01029922e-02  8.84832535e-03\n",
      "  1.85897108e-02  3.69047001e-02 -5.65769821e-02  2.14246102e-02\n",
      "  1.24713285e-02 -5.76916747e-02 -4.61020879e-03  7.48319030e-02\n",
      "  1.96703617e-03  2.72212084e-03  5.56941666e-02  1.78854540e-02\n",
      " -6.21019602e-02  9.49405730e-02 -7.77218910e-03 -4.54246476e-02\n",
      "  1.47631876e-02 -5.06241666e-03  2.36852635e-02 -8.52439925e-02\n",
      " -4.14429698e-03 -1.28681669e-02 -2.49696858e-02 -4.48643113e-04\n",
      " -2.94885994e-03  7.51215685e-03 -4.56848815e-02  1.89320988e-03\n",
      "  1.79614387e-02 -1.98163223e-02  5.08921109e-02 -5.01765497e-02\n",
      " -4.66578826e-02 -3.86618674e-02 -3.03664897e-02  3.17865759e-02\n",
      " -3.87183987e-02 -6.99096639e-03  2.70361397e-02 -1.85461435e-02\n",
      "  4.56584385e-03  5.85621968e-03  2.39914805e-02  2.27459967e-02\n",
      "  6.16354728e-03 -1.40758343e-02  7.94903841e-03 -2.47938782e-02\n",
      " -6.19506165e-02  6.27293775e-04 -6.24674838e-03 -2.60942318e-02\n",
      "  4.01825365e-03  2.85272188e-02  2.83167185e-03  6.21718448e-03\n",
      "  9.56937671e-03  2.02708822e-02  6.30678423e-03 -9.44270417e-02\n",
      " -1.21531179e-02  7.18323141e-03 -7.45823234e-02 -7.08706230e-02\n",
      " -1.79980379e-02  1.13763437e-02  2.47825999e-02 -3.62120979e-02\n",
      "  1.58199668e-02  5.01832217e-02  5.39580397e-02  6.93829507e-02\n",
      " -3.82490922e-03  2.04013065e-02 -4.30115201e-02 -5.75991394e-03\n",
      "  3.02039795e-02  1.57483704e-02  4.94919643e-02  1.43886199e-02\n",
      " -5.44079877e-02 -4.12555672e-02  6.92268610e-02  2.42457874e-02\n",
      " -5.14188483e-02 -5.34210950e-02  1.58925205e-02 -1.50358956e-02\n",
      " -2.25678775e-02  2.58841030e-02 -4.77324054e-02 -1.70809347e-02\n",
      " -3.45599391e-02  1.69997010e-02 -4.90905493e-02 -1.33929041e-03\n",
      "  4.06927317e-02 -2.02961918e-02 -8.03493112e-02 -1.14617962e-02\n",
      " -2.92013995e-02  1.41150961e-02 -1.96730229e-03 -2.41573658e-02\n",
      " -2.76098773e-02  2.40243319e-02 -9.02607292e-03  5.54302568e-03\n",
      " -1.44320633e-02  3.61689888e-02 -4.14039791e-02 -2.58237701e-02\n",
      " -1.05315819e-02 -5.81710748e-02  1.38424141e-02  5.19632420e-04\n",
      "  5.94718307e-02  4.93903607e-02 -2.92967521e-02  1.06758028e-02\n",
      " -2.26421710e-02  1.73780434e-02  2.52650864e-03  1.60654020e-02\n",
      "  3.24902907e-02  4.06766422e-02  4.83727269e-02  4.51828204e-02\n",
      " -1.20800203e-02  1.48456823e-02 -3.02811842e-02 -5.17218420e-03\n",
      " -9.61064100e-02  5.33604957e-02  4.40234467e-02  5.40165231e-03\n",
      "  7.81947188e-03  5.77781089e-02 -4.87991087e-02  1.68877430e-02\n",
      "  7.11308327e-03  3.38933654e-02 -6.88633770e-02 -1.42704770e-02\n",
      " -1.38707859e-02 -2.99146809e-02  2.57660653e-02 -2.13152040e-02\n",
      " -3.43817137e-02 -2.48068701e-02 -2.49935612e-02 -7.86170736e-02\n",
      "  3.06980442e-02  1.45327514e-02 -5.41489804e-03  4.73781712e-02\n",
      " -7.01190308e-02  1.13144917e-02  4.95405076e-03 -3.55000165e-03\n",
      "  1.29097244e-02  2.32604723e-02 -9.73814353e-03  3.40375453e-02\n",
      "  6.32925481e-02  1.34643055e-02  1.56003479e-02 -3.18665579e-02\n",
      "  7.38162622e-02 -2.33753473e-02  9.54554379e-02  2.57141814e-02\n",
      "  2.40740664e-02  2.43897680e-02  9.86579107e-06  2.18031481e-02\n",
      " -9.55742598e-03 -4.50729690e-02 -1.55274523e-02  7.77497441e-02\n",
      " -7.72792920e-02  2.25793272e-02  4.32315767e-02 -5.17063414e-33\n",
      " -1.79025978e-02 -4.39102873e-02  5.95975816e-02  2.66227629e-02\n",
      " -4.63029779e-02  5.12289116e-03 -3.56424525e-02  6.18635444e-03\n",
      " -3.38567831e-02  3.27491276e-02 -1.61050484e-02 -1.01101929e-02\n",
      "  1.52029209e-02 -4.55011055e-02  3.46567109e-02 -1.31760761e-02\n",
      "  2.96436623e-02 -2.15799790e-02 -3.04189771e-02  2.44694706e-02\n",
      " -3.30228433e-02 -3.29086669e-02  3.69796082e-02  5.48559241e-02\n",
      "  8.88678581e-02 -1.95463952e-02 -2.00882498e-02 -2.28787791e-02\n",
      " -7.22887963e-02 -4.21564700e-03  1.13199754e-02 -8.09095055e-03\n",
      "  5.35513880e-03 -1.08259637e-03 -6.22563879e-04  8.06100219e-02\n",
      "  7.56929629e-03 -6.36097342e-02  1.91120338e-02 -4.92263818e-03\n",
      " -9.71231684e-02 -1.20471073e-02 -6.31824806e-02 -6.76516350e-03\n",
      "  6.82291435e-03 -5.43364212e-02 -9.10481252e-03 -4.44083363e-02\n",
      "  8.33728723e-03 -1.08845606e-02  6.45905174e-03  6.91638701e-03\n",
      " -2.71163788e-03 -2.84852809e-03  1.45750381e-02  1.19754545e-01\n",
      " -8.85526091e-03 -2.57062316e-02  2.28433870e-02  1.81173030e-02\n",
      "  4.41121310e-02  7.10650086e-02 -3.31217796e-02  1.73801892e-02\n",
      " -2.74641179e-02 -1.60487054e-03  3.25477533e-02 -1.71236191e-02\n",
      "  6.69180090e-03  5.67781664e-02  2.72063408e-02  6.85422644e-02\n",
      "  3.67534198e-02  1.14294536e-01 -3.78032513e-02 -5.26040383e-02\n",
      "  1.57587032e-03  5.61155081e-02 -1.07011618e-02 -4.88736816e-02\n",
      " -1.80311967e-02 -2.73587778e-02 -4.31184238e-03 -4.46846560e-02\n",
      " -2.25107782e-02 -1.91809982e-02 -1.46813998e-02  4.10894826e-02\n",
      "  1.11537762e-02 -1.68196391e-02  3.08983065e-02  6.98865578e-02\n",
      "  4.12445366e-02 -2.21354235e-02 -1.33474553e-02  8.93157721e-02\n",
      " -1.25482827e-02 -3.82187753e-03 -2.94459052e-02 -2.86387596e-02\n",
      " -3.15691791e-02 -4.93966192e-02 -5.40600084e-02 -8.55880603e-03\n",
      "  2.22159997e-02 -3.29532176e-02 -5.38377725e-02  3.19165587e-02\n",
      " -5.09893149e-02 -2.57090591e-02  3.22660990e-02  1.65171716e-02\n",
      "  2.79500913e-02 -2.05819290e-02 -7.98556060e-02  4.10980824e-03\n",
      "  4.11101431e-02  1.14898244e-02 -3.96933444e-02 -4.80248816e-02\n",
      " -2.70446334e-02  6.50602132e-02 -2.79092211e-02 -1.03561124e-02\n",
      "  5.41942986e-03  2.76410468e-02  4.92581800e-02  4.99094725e-02\n",
      "  1.06258274e-04 -3.70162018e-02 -4.37660143e-02  6.62259012e-03\n",
      "  2.10606956e-07  4.86529469e-02  3.59919742e-02  6.34945855e-02\n",
      " -1.02877812e-02  1.50931673e-02  3.68953845e-03 -3.09141465e-02\n",
      " -1.76841170e-02  9.11462773e-03  5.03438152e-02  5.95971122e-02\n",
      "  1.08037954e-02 -2.24125907e-02  7.53756193e-03 -8.12842250e-02\n",
      "  4.76694070e-02 -3.94507237e-02 -1.19266026e-01  1.03270561e-02\n",
      "  3.99158802e-03  1.88188273e-02 -1.97469387e-02 -5.59292994e-02\n",
      " -2.66937502e-02 -1.42273996e-02 -2.62955278e-02 -1.48637202e-02\n",
      " -3.96788567e-02  1.66336652e-02  6.58494383e-02 -3.23070027e-02\n",
      " -7.33149722e-02  3.85435410e-02  6.42825440e-02 -8.00722744e-03\n",
      " -4.94604260e-02  8.18032492e-03  9.70508624e-03  2.63822265e-02\n",
      "  5.65599427e-02 -4.35374193e-02 -4.08889763e-02 -1.27074681e-02\n",
      " -1.38013531e-02  6.22712122e-03  7.58728310e-02  3.46967988e-02\n",
      " -7.10834414e-02  4.50641103e-02  3.53036709e-02  2.09584609e-02\n",
      "  1.44743351e-02  2.32403539e-03 -2.44410634e-02  3.63392308e-02\n",
      " -2.35463046e-02  1.89676657e-02 -2.60355398e-02 -9.93231498e-03\n",
      "  5.56439720e-02 -6.05445653e-02  9.16889403e-03 -2.97900792e-02\n",
      "  1.38168097e-01  1.07981786e-02  3.26499715e-02  4.57227184e-03\n",
      "  9.70711870e-35  5.44159440e-03 -9.28576365e-02 -4.84296381e-02\n",
      "  2.79862247e-02 -3.05133797e-02  3.27194226e-03  3.13943475e-02\n",
      " -5.84330456e-03 -3.23214270e-02  2.86812857e-02 -6.73663104e-03]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "embedding_model = SentenceTransformer(model_name_or_path=\"all-mpnet-base-v2\", device=\"cuda\")\n",
    "test = \"This is a test text!!\"\n",
    "embedding = embedding_model.encode(test)\n",
    "print(\"embedding shape: \", embedding.shape)\n",
    "print(\"embedding values: \", embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea4a0838-026d-46a8-bee4-8ebe34c9c449",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 450/450 [00:43<00:00, 10.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU time: 43.26 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 450/450 [00:07<00:00, 58.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU time: 7.74 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# here just a speed test for creating the embeddings\n",
    "# my local CPU VS my local GPU (Nividia RTX 3060)\n",
    "import time\n",
    "\n",
    "def create_embeddings(chunks, embedding_model):\n",
    "    # Embed each chunk one by one\n",
    "    for item in tqdm(chunks):\n",
    "        item[\"embedding\"] = embedding_model.encode(item[\"sentence_chunk\"])\n",
    "\n",
    "# cpu\n",
    "embedding_model.to(\"cpu\")\n",
    "t1 = time.time()\n",
    "create_embeddings(extracted_chunks_filtered, embedding_model)\n",
    "t2 = time.time()\n",
    "print(f\"CPU time: {round(t2 - t1, 2)} s\" )\n",
    "\n",
    "# gpu\n",
    "embedding_model.to(\"cuda\")\n",
    "t1 = time.time()\n",
    "create_embeddings(extracted_chunks_filtered, embedding_model)\n",
    "t2 = time.time()\n",
    "print(f\"GPU time: {round(t2 - t1, 2)} s\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af02167-7243-4988-908b-aa20b05c6de2",
   "metadata": {},
   "source": [
    "Embed all texts in batches: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c54c9365-76e9-4ae8-8c79-746cdc69bef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU time batched: 57.83 s\n"
     ]
    }
   ],
   "source": [
    "text_chunks = [item[\"sentence_chunk\"] for item in extracted_chunks_filtered]\n",
    "embedding_model.to(\"cpu\")\n",
    "t1 = time.time()\n",
    "text_chunk_embeddings = embedding_model.encode(text_chunks,\n",
    "                                               batch_size=32,\n",
    "                                               convert_to_tensor=True) \n",
    "t2 = time.time()\n",
    "print(f\"CPU time batched: {round(t2 - t1, 2)} s\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "554ac034-eb18-4fa6-a482-735af4734231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU time batched: 3.4 s\n"
     ]
    }
   ],
   "source": [
    "text_chunks = [item[\"sentence_chunk\"] for item in extracted_chunks_filtered]\n",
    "embedding_model.to(\"cuda\")\n",
    "t1 = time.time()\n",
    "text_chunk_embeddings = embedding_model.encode(text_chunks,\n",
    "                                               batch_size=32,\n",
    "                                               convert_to_tensor=True) \n",
    "t2 = time.time()\n",
    "print(f\"GPU time batched: {round(t2 - t1, 2)} s\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19e57674-ad6b-4494-958f-2b7b4f5f3320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save embeddings to file\n",
    "import csv\n",
    "embeddings_df = pd.DataFrame(extracted_chunks_filtered)\n",
    "embeddings_df_save_path = \"embeddings.csv\"\n",
    "embeddings_df.to_csv(embeddings_df_save_path, index=False, escapechar=\"\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a31be3de-134c-4271-afa2-bac78278489e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>page_number</th>\n",
       "      <th>sentence_chunk</th>\n",
       "      <th>chunk_char_count</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data\\\\attention is all you need.pdf</td>\n",
       "      <td>0</td>\n",
       "      <td>Provided proper attribution is provided, Googl...</td>\n",
       "      <td>1165</td>\n",
       "      <td>154</td>\n",
       "      <td>291.25</td>\n",
       "      <td>[ 2.07077805e-02  2.70413030e-02 -1.68691296e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data\\\\attention is all you need.pdf</td>\n",
       "      <td>0</td>\n",
       "      <td>Our model achieves 28.4 BLEU on the WMT 2014 E...</td>\n",
       "      <td>620</td>\n",
       "      <td>95</td>\n",
       "      <td>155.00</td>\n",
       "      <td>[ 1.10328430e-03  5.08999750e-02  3.29319574e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data\\\\attention is all you need.pdf</td>\n",
       "      <td>0</td>\n",
       "      <td>Jakob proposed replacing RNNs with self-attent...</td>\n",
       "      <td>658</td>\n",
       "      <td>90</td>\n",
       "      <td>164.50</td>\n",
       "      <td>[ 1.54208224e-02  1.14086864e-03 -6.22348813e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data\\\\attention is all you need.pdf</td>\n",
       "      <td>0</td>\n",
       "      <td>Lukasz and Aidan spent countless long days des...</td>\n",
       "      <td>392</td>\n",
       "      <td>49</td>\n",
       "      <td>98.00</td>\n",
       "      <td>[ 2.14229785e-02  5.34767583e-02 -1.31562511e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data\\\\attention is all you need.pdf</td>\n",
       "      <td>1</td>\n",
       "      <td>1 Introduction Recurrent neural networks, long...</td>\n",
       "      <td>1115</td>\n",
       "      <td>158</td>\n",
       "      <td>278.75</td>\n",
       "      <td>[-2.53893668e-03  4.21451516e-02 -5.52566350e-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             file_path  page_number  \\\n",
       "0  data\\\\attention is all you need.pdf            0   \n",
       "1  data\\\\attention is all you need.pdf            0   \n",
       "2  data\\\\attention is all you need.pdf            0   \n",
       "3  data\\\\attention is all you need.pdf            0   \n",
       "4  data\\\\attention is all you need.pdf            1   \n",
       "\n",
       "                                      sentence_chunk  chunk_char_count  \\\n",
       "0  Provided proper attribution is provided, Googl...              1165   \n",
       "1  Our model achieves 28.4 BLEU on the WMT 2014 E...               620   \n",
       "2  Jakob proposed replacing RNNs with self-attent...               658   \n",
       "3  Lukasz and Aidan spent countless long days des...               392   \n",
       "4  1 Introduction Recurrent neural networks, long...              1115   \n",
       "\n",
       "   chunk_word_count  chunk_token_count  \\\n",
       "0               154             291.25   \n",
       "1                95             155.00   \n",
       "2                90             164.50   \n",
       "3                49              98.00   \n",
       "4               158             278.75   \n",
       "\n",
       "                                           embedding  \n",
       "0  [ 2.07077805e-02  2.70413030e-02 -1.68691296e-...  \n",
       "1  [ 1.10328430e-03  5.08999750e-02  3.29319574e-...  \n",
       "2  [ 1.54208224e-02  1.14086864e-03 -6.22348813e-...  \n",
       "3  [ 2.14229785e-02  5.34767583e-02 -1.31562511e-...  \n",
       "4  [-2.53893668e-03  4.21451516e-02 -5.52566350e-...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import saved file and view\n",
    "embeddings_loaded_df = pd.read_csv(embeddings_df_save_path)\n",
    "embeddings_loaded_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5431cf26-5bd7-40bb-a647-92a3845f63af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ae8f18-ee9e-45c1-ab60-adea60409e10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
